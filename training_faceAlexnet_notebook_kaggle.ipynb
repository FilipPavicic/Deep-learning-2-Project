{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T14:33:24.002896Z","iopub.status.busy":"2023-01-03T14:33:24.001748Z","iopub.status.idle":"2023-01-03T14:33:24.027873Z","shell.execute_reply":"2023-01-03T14:33:24.026805Z","shell.execute_reply.started":"2023-01-03T14:33:24.002765Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/kaggle/input/du2project-code/project')"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T14:38:36.191521Z","iopub.status.busy":"2023-01-03T14:38:36.191130Z","iopub.status.idle":"2023-01-03T14:38:36.198497Z","shell.execute_reply":"2023-01-03T14:38:36.196837Z","shell.execute_reply.started":"2023-01-03T14:38:36.191488Z"},"trusted":true},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import torch\n","import torchvision\n","import torch.utils.data as data\n","import os\n","from os.path import join\n","import argparse\n","import logging\n","from tqdm import tqdm\n","from torchvision.utils import save_image\n","#user import\n","from data_generator.DataLoader_Pretrain_Alexnet import CACD\n","from model.GAN import IPCGANs\n","from utils.io import check_dir,Img_to_zero_center,Reverse_zero_center\n","from datetime import datetime"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T14:35:27.702230Z","iopub.status.busy":"2023-01-03T14:35:27.701355Z","iopub.status.idle":"2023-01-03T14:35:27.707659Z","shell.execute_reply":"2023-01-03T14:35:27.706767Z","shell.execute_reply.started":"2023-01-03T14:35:27.702185Z"},"trusted":true},"outputs":[],"source":["TIMESTAMP = \"{0:%Y-%m-%d_%H-%M-%S}\".format(datetime.now())"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T13:53:22.430568Z","iopub.status.busy":"2023-01-03T13:53:22.429996Z","iopub.status.idle":"2023-01-03T13:53:22.442310Z","shell.execute_reply":"2023-01-03T13:53:22.441251Z","shell.execute_reply.started":"2023-01-03T13:53:22.430525Z"},"trusted":true},"outputs":[],"source":["class dotdict(dict):\n","    \"\"\"dot.notation access to dictionary attributes\"\"\"\n","    __getattr__ = dict.get\n","    __setattr__ = dict.__setitem__\n","    __delattr__ = dict.__delitem__\n","    \n","    \n","args = {\n","    'learning_rate' : 1e-4,\n","    'batch_size' : 256,\n","    'max_epoches' : 200,\n","    'val_interval' : 20000,\n","    'save_interval' : 20000, \n","    'cuda_device' : '0',\n","    'checkpoint' : '/kaggle/working/checkpoint/pretrain_alexnet',\n","    'saved_model_folder' : '/kaggle/working/checkpoint/pretrain_alexnet/saved_parameters',\n","    'list_root' : '/kaggle/input/du2project-code/project/data/cacd2000-lists',\n","    'data_root' : '/kaggle/input/du2project-data/CACD2000',\n","    \n","}\n","\n","args_local = {\n","    'learning_rate' : 1e-4,\n","    'batch_size' : 16,\n","    'max_epoches' : 200,\n","    'val_interval' : 20000,\n","    'save_interval' : 20000, \n","    'cuda_device' : '0',\n","    'checkpoint' : './checkpoint/pretrain_alexnet/',\n","    'saved_model_folder' : './checkpoint/pretrain_alexnet/saved_parameters',\n","    'list_root' : './data/cacd2000-lists',\n","    'data_root' : './CACD2000',\n","    \n","}\n","\n","args = dotdict(args_local)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T13:27:39.105535Z","iopub.status.busy":"2023-01-03T13:27:39.104690Z","iopub.status.idle":"2023-01-03T13:27:39.110976Z","shell.execute_reply":"2023-01-03T13:27:39.109908Z","shell.execute_reply.started":"2023-01-03T13:27:39.105497Z"},"trusted":true},"outputs":[],"source":["os.makedirs(args.checkpoint)\n","os.makedirs(args.saved_model_folder)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T13:28:15.724790Z","iopub.status.busy":"2023-01-03T13:28:15.724428Z","iopub.status.idle":"2023-01-03T13:28:16.313154Z","shell.execute_reply":"2023-01-03T13:28:16.311480Z","shell.execute_reply.started":"2023-01-03T13:28:15.724760Z"},"trusted":true},"outputs":[],"source":["from model.faceAlexnet import AgeClassify\n","model=AgeClassify()\n","optim=model.optim"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T13:53:28.722097Z","iopub.status.busy":"2023-01-03T13:53:28.721179Z","iopub.status.idle":"2023-01-03T13:53:29.456426Z","shell.execute_reply":"2023-01-03T13:53:29.455435Z","shell.execute_reply.started":"2023-01-03T13:53:28.722026Z"},"trusted":true},"outputs":[],"source":["transforms = torchvision.transforms.Compose([\n","        torchvision.transforms.Resize((227, 227)),\n","        torchvision.transforms.ToTensor(),\n","        Img_to_zero_center()\n","    ])\n","#step4: define train/test dataloader\n","train_dataset = CACD(\n","    list_root = args.list_root, \n","    data_root= args.data_root, \n","    split = \"train\",\n","    transforms=transforms, label_transforms=None\n",")\n","test_dataset = CACD(\n","    list_root = args.list_root, \n","    data_root= args.data_root, \n","    split = \"test\",\n","    transforms=transforms, label_transforms=None\n",")\n","train_loader = torch.utils.data.DataLoader(\n","    dataset=train_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    dataset=test_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T13:53:38.984299Z","iopub.status.busy":"2023-01-03T13:53:38.983920Z","iopub.status.idle":"2023-01-03T13:54:54.309408Z","shell.execute_reply":"2023-01-03T13:54:54.307777Z","shell.execute_reply.started":"2023-01-03T13:53:38.984266Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 5/9184 [00:01<54:46,  2.79it/s, cls_loss=1.557]  \n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './CACD2000\\\\36_Penélope_Cruz_0015.jpg'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Filip\\Desktop\\DUBUC2\\project\\Deep-learning-2-Project\\training_faceAlexnet_notebook_kaggle.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Filip/Desktop/DUBUC2/project/Deep-learning-2-Project/training_faceAlexnet_notebook_kaggle.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args\u001b[39m.\u001b[39mmax_epoches):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Filip/Desktop/DUBUC2/project/Deep-learning-2-Project/training_faceAlexnet_notebook_kaggle.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(train_loader),total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Filip/Desktop/DUBUC2/project/Deep-learning-2-Project/training_faceAlexnet_notebook_kaggle.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m train_idx, (img,label) \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Filip/Desktop/DUBUC2/project/Deep-learning-2-Project/training_faceAlexnet_notebook_kaggle.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         img\u001b[39m=\u001b[39mimg\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Filip/Desktop/DUBUC2/project/Deep-learning-2-Project/training_faceAlexnet_notebook_kaggle.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         label\u001b[39m=\u001b[39mlabel\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\Filip\\Desktop\\DUBUC2\\project\\Deep-learning-2-Project\\data_generator\\DataLoader_Pretrain_Alexnet.py:42\u001b[0m, in \u001b[0;36mCACD.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     41\u001b[0m     img_path, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_labels[idx]\n\u001b[1;32m---> 42\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\n\u001b[0;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m         img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\PIL\\Image.py:3092\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3089\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3091\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3092\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3093\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3095\u001b[0m \u001b[39mtry\u001b[39;00m:\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './CACD2000\\\\36_Penélope_Cruz_0015.jpg'"]}],"source":["for epoch in range(args.max_epoches):\n","    pbar = tqdm(enumerate(train_loader),total = len(train_loader))\n","    for train_idx, (img,label) in pbar:\n","        img=img.cuda()\n","        label=label.type(torch.LongTensor)\n","        label=label.cuda()\n","\n","        #train\n","        optim.zero_grad()\n","        model.train(img,label)\n","        loss=model.loss\n","        loss.backward()\n","        optim.step()\n","        format_str = ('step %d/%d, cls_loss = %.3f')\n","        pbar.set_postfix({'cls_loss': '%.3f' %(loss)})\n","\n","\n","        # save the parameters at the end of each save interval\n","        if train_idx*args.batch_size % args.save_interval == 0 and train_idx != 0:\n","            model.save_model(dir=args.saved_model_folder,\n","                             filename='epoch_%d_iter_%d.pth'%(epoch, train_idx))\n","            print('checkpoint has been created!')\n","\n","        #val step\n","\n","        if train_idx % args.val_interval == 0 and train_idx != 0:\n","            train_correct=0\n","            train_total=0\n","            with torch.no_grad():\n","                for val_img,val_label in tqdm(test_loader):\n","                    val_img=val_img.cuda()\n","                    val_label=val_label.cuda()\n","                    output=model.val(val_img)\n","                    train_correct += (output == val_label).sum()\n","                    train_total += val_img.size()[0]\n","\n","            print('validate has been finished!')\n","            format_str = ('val_acc = %.3f')\n","            print(format_str % (train_correct.cpu().numpy()/train_total))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"9c86a5f9a16365ea3578b53e3588f42424d26dfff66e99e0a69d98262d003c14"}}},"nbformat":4,"nbformat_minor":4}
